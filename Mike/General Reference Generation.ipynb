{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "shaped-mexico",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "Studying dataset to look for opportunities to compress. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-matrix",
   "metadata": {},
   "source": [
    "1. Look at sampling k-mers for frequency analysis\n",
    "2. Because the BWT gets a ton of nice repeats, does this mean that we might get a set of most frequent k-mers that occur even more frequently after running BWT? Let's explore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"100bacteria\"\n",
    "FOLDER_NAME = \"genome_compression_datasets\"\n",
    "sample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = []\n",
    "benchmark_results = []\n",
    "# Compress standard data\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "dataset_fp = os.path.join(home, FOLDER_NAME, \"datasets\", f\"dataset_{str(dataset)}\")\n",
    "break_counter = 0\n",
    "for fasta in os.listdir(dataset_fp):\n",
    "    if sample is not None and break_counter >= sample:\n",
    "        break\n",
    "    # Ignore DS_Store and other hidden files\n",
    "    #k = 50000\n",
    "    if fasta.endswith('fna.gz'):\n",
    "        fasta_fp = os.path.join(dataset_fp, fasta)\n",
    "        try:\n",
    "            with gzip.open(fasta_fp, \"rt\") as handle:\n",
    "                # If want to consider filesize: print(os.fstat(handle.fileno()).st_size)\n",
    "                total_genome = \"\"\n",
    "                for record in SeqIO.parse(handle, \"fasta\"):\n",
    "                    # sometimes genomes stored across records\n",
    "                    total_genome += record.seq\n",
    "                genomes.append(total_genome)\n",
    "                #for x in range(len(total_genome)//k):\n",
    "                #    genomes.append(total_genome[x*k:x*k + k])\n",
    "            break_counter += 1\n",
    "        except:\n",
    "            print(f\"Couldn't do {fasta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = [str(g) for g in genomes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "genomes = [str(g) for g in sample(genomes, 52)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- # matches with & without burrow's wheeler\n",
    "- # matches as number of k-mers increases proportional to number of k-mers\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_process import substring_finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "len([x for x in itertools.combinations([x for x in range(len(genomes[:50]))], 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "pool = Pool(10)\n",
    "out = pool.map(substring_finder, ((genomes[x[0]], genomes[x[1]]) for x in itertools.combinations([x for x in range(len(genomes[:50]))], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"mer50000_sample50.txt\", \"w+\")\n",
    "for o in out:\n",
    "    for match in o:\n",
    "        f.write(f\"{match}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = [item for sublist in out for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "counter=collections.Counter(agg)\n",
    "counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "match_list = []\n",
    "for c in list(itertools.combinations([x for x in range(len(genomes))], 2)):\n",
    "    s = SequenceMatcher(None, genomes[c[0]], genomes[c[1]])\n",
    "    matches = s.get_matching_blocks()\n",
    "    for m in matches:\n",
    "        if m.size > 1:\n",
    "            match_list.append(genomes[c[0]][m.a:m.a+matches[0].size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-finger",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "match_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-petersburg",
   "metadata": {},
   "source": [
    "Begin looking at BWT.... Found it isn't really practical to run BWT on genomes due to their length....much more suited towards individual protein-coding sequences, perhaps? Something shorter than a genome..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-ribbon",
   "metadata": {},
   "source": [
    "Conclusion: While BWT may produce some great results, the resources it requires to run at scale exceeds our current computational resources. We pursue shall pursue other methods..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "from burrowswheeler import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_genomes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in genomes[:10]:\n",
    "    transformed_genomes.append(transform(str(g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from difflib import SequenceMatcher\n",
    "match_list_trans = []\n",
    "for c in list(itertools.combinations([x for x in range(len(transformed_genomes))], 2)):\n",
    "    s = SequenceMatcher(None, transformed_genomes[c[0]], transformed_genomes[c[1]])\n",
    "    matches = s.get_matching_blocks()\n",
    "    for m in matches:\n",
    "        if m.size > 1:\n",
    "            match_list_trans.append(transformed_genomes[c[0]][m.a:m.a+matches[0].size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_list_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-department",
   "metadata": {},
   "source": [
    "## Resampling k-mers by size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-viking",
   "metadata": {},
   "source": [
    "Decided to resample <=64 best 10-mers to use as reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-clear",
   "metadata": {},
   "source": [
    "Resampled again based on k defined in data_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_process import substring_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_set = substring_counter(genomes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "pool = Pool(10)\n",
    "out = pool.map(substring_counter, genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_set = {}\n",
    "for s in out:\n",
    "    for kmer in s:\n",
    "        if kmer not in master_set:\n",
    "            master_set[kmer] = 0\n",
    "        master_set[kmer] += s[kmer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "counter=collections.Counter(master_set)\n",
    "most_common = counter.most_common(8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in [64, 32, 16, 8, 4]:\n",
    "    f = open(f'references/14mer_{str(num)}.txt', 'w+')\n",
    "    for x in range(num):\n",
    "        f.write(f\"{most_common[x][0]}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10: ~20k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_python3",
   "language": "python",
   "name": "base_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
