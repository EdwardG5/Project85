{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "portable-disney",
   "metadata": {},
   "source": [
    "## Creating a Universal Reference Compressor\n",
    "There exist two approaches here\n",
    "1. Linearly assign $(n^2)$\n",
    "2. Dynamic programming to assign absolute optimal compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-consent",
   "metadata": {},
   "source": [
    "### Linear Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree(d, keys):\n",
    "    for k in keys:\n",
    "        d = d[k]\n",
    "    return d\n",
    "\n",
    "def set_tree(d, keys, value):\n",
    "    d = get_tree(d, keys)\n",
    "    d[value] = {}\n",
    "    \n",
    "def get_indices(d):\n",
    "    for k in d.keys():\n",
    "        if type(k) == tuple:\n",
    "            return k\n",
    "    return ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(reference):\n",
    "    tree = {}\n",
    "    # Convert reference into tree\n",
    "    for i in range(len(reference)):\n",
    "        if (i != 0 and i % 10000 == 0):\n",
    "            print(i)\n",
    "        for j in range(i, len(reference)):\n",
    "            parents = [reference[x] for x in range(j-i,j)]\n",
    "            set_tree(tree, parents, reference[j])\n",
    "            set_tree(tree, parents + [reference[j]], (j-len(parents),j))\n",
    "    return tree\n",
    "def linear_ref_compress(reference, compress, tree):        \n",
    "    compressed_ref = []\n",
    "    temp_tree = tree\n",
    "    for i in range(len(compress)):\n",
    "        #print(compress[i])\n",
    "        #print(temp_tree.keys())\n",
    "        if compress[i] in temp_tree:\n",
    "            temp_tree = temp_tree[compress[i]]\n",
    "            if len(temp_tree.keys()) > 1:\n",
    "                next\n",
    "            else:\n",
    "                #print(get_indices(temp_tree))\n",
    "                compressed_ref.append(get_indices(temp_tree))\n",
    "                temp_tree = tree\n",
    "        else:\n",
    "            #print(get_indices(temp_tree))\n",
    "            compressed_ref.append(get_indices(temp_tree))\n",
    "            temp_tree = tree[compress[i]]\n",
    "    final_index = get_indices(temp_tree)\n",
    "    if final_index != ():\n",
    "        compressed_ref.append(final_index)\n",
    "    return compressed_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = \"ACGTACTGACTG\"\n",
    "compress = \"ACGTACTGACTG\"\n",
    "linear_ref_compress(reference, compress, build_tree(reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(char):\n",
    "    char_dict = {\"A\": \"000\", \"C\": \"001\", \"T\":\"010\", \"G\":\"011\", \"N\":\"100\", \"-\":\"101\", \"_ref\": \"111\"}\n",
    "    return char_dict[char]\n",
    "def compress_regular(genome):\n",
    "    out_genome = \"\"\n",
    "    for g in genome:\n",
    "        out_genome += binarize(g)\n",
    "    return out_genome\n",
    "def linear_ref_compress_genome(reference):\n",
    "    tree = build_tree(reference)\n",
    "    def compress_genome(genome):\n",
    "        char_dict = {\"A\": \"000\", \"C\": \"001\", \"T\":\"010\", \"G\":\"011\", \"N\":\"100\", \"-\":\"101\", \"_ref\": \"111\"}\n",
    "        ref_indices = linear_ref_compress(reference, genome, tree)\n",
    "        compressed = \"\"\n",
    "        for (start, end) in ref_indices:\n",
    "            if (end-start) > 6:\n",
    "                compressed += binarize(\"_ref\")\n",
    "                compressed += str('{:08b}'.format(start))\n",
    "                compressed += str('{:08b}'.format(end))\n",
    "            else:\n",
    "                for x in range(start, end+1):\n",
    "                    compressed += binarize(reference[x])\n",
    "        return compressed\n",
    "    return compress_genome\n",
    "def linear_ref_decompress_genome(reference):\n",
    "    def decompress_genome(compressed):\n",
    "        char_dict = {\"A\": \"000\", \"C\": \"001\", \"T\":\"010\", \"G\":\"011\", \"N\":\"100\", \"-\":\"101\", \"_ref\": \"111\"}\n",
    "        rev_dict = {char_dict[k]:k for k in char_dict.keys()}\n",
    "        i = 0\n",
    "        decompressed = \"\"\n",
    "        while i < len(compressed):\n",
    "            tag = rev_dict[compressed[i:i+3]]\n",
    "            if tag == \"_ref\":\n",
    "                i += 3\n",
    "                start = int(compressed[i:i+8], 2)\n",
    "                i += 8\n",
    "                end = int(compressed[i:i+8], 2)\n",
    "                i += 8\n",
    "                decompressed += reference[start:end+1]\n",
    "            else:\n",
    "                i += 3\n",
    "                decompressed += tag\n",
    "        return decompressed\n",
    "    return decompress_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = \"ACGATCGACTGACTGACTGACTAGCT\"\n",
    "compress = \"ACGTACGATCGACTAGCTACGATCG\"\n",
    "compress_func = linear_ref_compress_genome(reference)\n",
    "decompress_func = linear_ref_decompress_genome(reference)\n",
    "assert(decompress_func(compress_func(compress)) == compress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_process import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-tackle",
   "metadata": {},
   "source": [
    "## Testing Random Reference\n",
    "Now, let's take a random bacteria genome as a reference for 10 different bacteria genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reference(ref_length):\n",
    "    import time\n",
    "    dataset = \"100bacteria\"\n",
    "    reference = get_genomes(dataset, sample=1)[0][:ref_length]\n",
    "    for letter in ['A', 'C', 'T', 'G', 'N', '-']:\n",
    "        if letter not in reference:\n",
    "            reference += letter\n",
    "    start_tree = time.time()\n",
    "    compress_func = linear_ref_compress_genome(reference)\n",
    "    end_tree = time.time()\n",
    "    df = benchmark_functions([compress_regular, compress_func], dataset=\"10bacteria\", sample=None)\n",
    "    end_compress = time.time()\n",
    "    return (df, end_tree - start_tree, end_compress - end_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-evans",
   "metadata": {},
   "source": [
    "Test by length of reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dict = {}\n",
    "for k in [10, 100, 500, 1000, 1500]:\n",
    "    performance_dict[k] = test_reference(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_compression(df):\n",
    "    return ((df['compress_regular_new_len'] - df['compress_genome_new_len']) / df['compress_regular_new_len'] * 100).to_frame('pct_compression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "performance_data = [[k, pct_compression(performance_dict[k][0]).mean()['pct_compression'], performance_dict[k][1], performance_dict[k][2]] for k in performance_dict.keys()]\n",
    "performance_df = pd.DataFrame(performance_data, columns=[\"reference length\", \"pct compression (%)\", \"time to produce tree (s)\", \"time to run benchmark (s)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df.plot(x='reference length', y='pct compression (%)', title=\"% Compression Achieved by Reference Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df.plot(x='reference length', y='time to produce tree (s)', title=\"Time to Build Tree by Reference Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df.plot(x='reference length', y='time to run benchmark (s)', title=\"Time to Run Benchmark by Reference Length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-duncan",
   "metadata": {},
   "source": [
    "## Adding Heuristics\n",
    "\n",
    "We know N and - present themselves heaps together so let's add some to this reference and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reference_heuristic(ref_length):\n",
    "    import time\n",
    "    dataset = \"100bacteria\"\n",
    "    reference = get_genomes(dataset, sample=1)[0][:ref_length-150]\n",
    "    # Add heuristic\n",
    "    reference += \"N\" * 100\n",
    "    reference += \"-\" * 50\n",
    "    for letter in ['A', 'C', 'T', 'G', 'N', '-']:\n",
    "        if letter not in reference:\n",
    "            reference += letter\n",
    "    start_tree = time.time()\n",
    "    compress_func = linear_ref_compress_genome(reference)\n",
    "    end_tree = time.time()\n",
    "    df = benchmark_functions([compress_regular, compress_func], dataset=\"10bacteria\", sample=None)\n",
    "    end_compress = time.time()\n",
    "    return (df, end_tree - start_tree, end_compress - end_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_H = test_reference_heuristic(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.DataFrame([\n",
    "    [\"Heuristic\", pct_compression(performance_H[0]).mean()['pct_compression']],\n",
    "    [\"No Heuristic\", pct_compression(performance_dict[1000][0]).mean()['pct_compression']]\n",
    "], columns=[\"Reference\", \"pct compression (%)\"])\n",
    "compare_df.plot.bar(x=\"Reference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-struggle",
   "metadata": {},
   "source": [
    "## Towards a universal reference...\n",
    "Now, with the groundwork done, this becomes an optimization problem.\n",
    "\n",
    "In the spirit of a computational biology class, we devise a genetic algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-piece",
   "metadata": {},
   "source": [
    "Initial idea: Due to limitations of computational power. I'm thinking of doing a generative approach on references of length 500 of which we can construct trees relatively quickly. Then concatenate these together to form our final reference. The beauty about this tree approach is, it is done ONCE and then never again. So it can really be however long we like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-brief",
   "metadata": {},
   "source": [
    "## Sequential Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "N = 26 # number of children to consider\n",
    "O = 2 # number of top old references to persist\n",
    "K = 500 # length of references\n",
    "GENERATIONS = 100\n",
    "R = 2 # number randoms per generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random(ref_length):\n",
    "    from random import randint\n",
    "    complete = None\n",
    "    while complete is None:\n",
    "        try:\n",
    "            k = randint(0,3)\n",
    "            gen = get_genomes(\"100bacteria\", sample=k)[k-1]\n",
    "            complete = True\n",
    "        except:\n",
    "            pass\n",
    "    start = randint(0,len(gen)-ref_length)\n",
    "    sample = gen[start:start+ref_length]\n",
    "    while any([b not in sample for b in ['A', 'C', 'T', 'G']]):\n",
    "        start = randint(0,len(gen)-ref_length)\n",
    "        sample = gen[start:start+ref_length]\n",
    "    sample = sample[:-100] + (\"N\" * 50) + (\"-\" * 50)\n",
    "    return sample\n",
    "\n",
    "def generate_random_reference(ref_length):\n",
    "    import random\n",
    "    \n",
    "    if random.random() > 0.9:\n",
    "        return sample_random(ref_length)\n",
    "    \n",
    "    # Heuristic: N normally occur in groups\n",
    "    # Heuristic: - normally occur individually or in groups\n",
    "    prob_dict = {\n",
    "        \"A\": 0.25,\n",
    "        \"C\": 0.25,\n",
    "        \"T\": 0.25,\n",
    "        \"G\": 0.25,\n",
    "    }\n",
    "    N_len = 50 # Number of N to add to reference\n",
    "    dash_len = 50 # Number of - to add to reference\n",
    "    N_dash_len = N_len + dash_len\n",
    "    \n",
    "    # Sample from probabilities dict\n",
    "    ref = \"\".join(random.choices(list(prob_dict.keys()), weights=prob_dict.values(), k=max(0, ref_length - N_dash_len)))\n",
    "    # Where to insert N list\n",
    "    insert_N_i = random.randint(0, len(ref))\n",
    "    ref = ref[:insert_N_i] + (\"N\" * N_len) + ref[insert_N_i:]\n",
    "    # Where to insert - list\n",
    "    insert_N_i = random.randint(0, len(ref))\n",
    "    ref = ref[:insert_N_i] + (\"-\" * dash_len) + ref[insert_N_i:]\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-wednesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_offspring(ref1, ref2):\n",
    "    import random\n",
    "    bases = ['A', 'C', 'T', 'G', 'N', '-']\n",
    "    assert(len(ref1) == len(ref2))\n",
    "    split_i = random.randint(0, len(ref1))\n",
    "    new = list(ref1[:split_i] + ref2[split_i:])\n",
    "    # mutate\n",
    "    for k in range(len(new)):\n",
    "        if random.random() > 0.98:\n",
    "            new[k] = bases[random.randint(0,5)]\n",
    "    return \"\".join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_scores(score_dict, generation):\n",
    "    with open(f\"genetic/scores_out_{N}_{K}.txt\", \"a+\") as f:\n",
    "        f.write(f\"Generation: {generation}\\n\")\n",
    "        for r in score_dict.keys():\n",
    "            f.write(f\"{r},{str(score_dict[r])}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    with open(f\"genetic/mean_pct_compression_{N}_{K}.txt\", \"a+\") as f:\n",
    "        avg_compression = sum(score_dict.values()) / len(score_dict.values())\n",
    "        f.write(f\"{generation},{str(avg_compression)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Generate initial references\n",
    "reference_universe = [generate_random_reference(K) for _ in range(N)]\n",
    "# Regular bitwise conversion\n",
    "reg_df = benchmark_functions([compress_regular], dataset=\"10bacteria\", sample=None)\n",
    "for g in range(GENERATIONS):\n",
    "    score_dict = {}\n",
    "    # Test all references\n",
    "    for r in reference_universe:\n",
    "        compress_func = linear_ref_compress_genome(r)\n",
    "        comp_df = benchmark_functions([compress_func], dataset=\"10bacteria\", sample=None)\n",
    "        score_dict[r] = ((reg_df['compress_regular_new_len'] - comp_df['compress_genome_new_len']) / reg_df['compress_regular_new_len'] * 100).to_frame('pct_compression').mean()['pct_compression']\n",
    "    \n",
    "    # Write scores\n",
    "    write_scores(score_dict, g)\n",
    "    \n",
    "    # Get new references\n",
    "    total_score = sum(score_dict.values())\n",
    "    prob_list = [k/total_score for k in score_dict.values()]\n",
    "    import random\n",
    "    parents = random.choices(list(score_dict.keys()), weights=prob_list, k=(2*N))\n",
    "    children = [produce_offspring(parents[i], parents[i+1]) for i in range(0, 2*N, 2)]\n",
    "    children += [generate_random_reference(K) for _ in range(R)]\n",
    "    reference_universe = children\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-liabilities",
   "metadata": {},
   "source": [
    "### Paralellized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_scores(score_list, ref_list, generation):\n",
    "    with open(f\"genetic/scores_out_{N}_{O}_{R}_{K}.txt\", \"a+\") as f:\n",
    "        f.write(f\"Generation: {generation}\\n\")\n",
    "        for r,s in zip(ref_list, score_list):\n",
    "            f.write(f\"{r},{str(s)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    with open(f\"genetic/mean_pct_compression_{N}_{O}_{R}_{K}.txt\", \"a+\") as f:\n",
    "        avg_compression = sum(score_list) / len(score_list)\n",
    "        f.write(f\"{generation},{str(avg_compression)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-thriller",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# Generate initial references\n",
    "reference_universe = [generate_random_reference(K) for _ in range(N + R + O)]\n",
    "# Regular bitwise conversion\n",
    "reg_df = benchmark_functions([compress_regular], dataset=\"100bacteria\", sample=20, check_atcg=True)\n",
    "for g in range(GENERATIONS):\n",
    "    start = time.time()\n",
    "    print(f\"Starting generation {g} with {len(reference_universe)} population\")\n",
    "    score_dict = {}\n",
    "    # Test all references\n",
    "    par_inputs = [(r, reg_df) for r in reference_universe]\n",
    "    from multiprocessing import Pool\n",
    "    pool = Pool(10)\n",
    "    score_list = pool.map(test_ref, par_inputs)\n",
    "    \n",
    "    # Write scores\n",
    "    write_scores(score_list, reference_universe, g)\n",
    "    \n",
    "    # Get new references\n",
    "    total_score = sum(score_list)\n",
    "    prob_list = [k/total_score for k in score_list]\n",
    "    import random\n",
    "    parents = random.choices(reference_universe, weights=prob_list, k=(2*N))\n",
    "    children = [produce_offspring(parents[i], parents[i+1]) for i in range(0, 2*N, 2)]\n",
    "    children += [generate_random_reference(K) for _ in range(R)]\n",
    "    \n",
    "    # add best old references to list\n",
    "    best_prob = sorted(range(len(prob_list)), key=lambda i:prob_list[i])[::-1][:O]\n",
    "    children += [reference_universe[k] for k in best_prob]\n",
    "    \n",
    "    reference_universe = children\n",
    "    end = time.time()\n",
    "    print(f\"Ending, taken {end - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('backup_refuni.txt', 'w+') as f:\n",
    "    for x in reference_universe:\n",
    "        f.write(f\"{x}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-parcel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_python3",
   "language": "python",
   "name": "base_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
